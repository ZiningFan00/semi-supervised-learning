{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu5BdPb99FrZ",
        "colab_type": "code",
        "outputId": "4f71a4b2-2616-43e7-ee87-0f6ac4b5573e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTING.md          main.ipynb               \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            "data_input.py            main.py                  randaugment.py\n",
            "efficientnet_builder.py  mnist_example.py         README.md\n",
            "efficientnet_model.py    noisystudent_svhn.ipynb  task_info.py\n",
            "ladder_net.py            pic_500.xlsx             utils.py\n",
            "LICENSE                  preprocessing.py\n",
            "\u001b[01;34mlocal_scripts\u001b[0m/           proc_svhn.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nSca7voBDvn",
        "colab_type": "code",
        "outputId": "ae2f765f-a55b-4396-ecbb-8aa2c61b5398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/final_code/noisystudent-master') # root dictionary, the parent folder root of train and test folder\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/final_code/noisystudent-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1hzMP-LN-U9",
        "colab_type": "code",
        "outputId": "beccb972-a193-4e11-e220-7004f2f54499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7va_2LfKLoj2",
        "colab_type": "code",
        "outputId": "94d64512-0527-46a4-e1a0-5bb5c3141d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sSsJNB-MBe9",
        "colab_type": "code",
        "outputId": "9fcd55a8-5c43-445c-9a45-5966ea6a377d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnbDGAKYCJqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path[0]='/tensorflow-1.15.2/python3.6'\n",
        "sys.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HRtJaK2GDDv",
        "colab_type": "code",
        "outputId": "26ab9f1e-bca0-43be-8aec-583720df7879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import keras\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "from ladder_net import get_ladder_network_fc\n",
        "\n",
        "inp_size = 28*28 # size of mnist dataset \n",
        "n_classes = 10\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, inp_size).astype('float32')/255\n",
        "x_test  = x_test.reshape(10000,  inp_size).astype('float32')/255\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
        "y_test  = keras.utils.to_categorical(y_test,  n_classes)\n",
        "\n",
        "idxs_label = range(x_train.shape[0])\n",
        "idxs_unlabel = range(x_train.shape[0])\n",
        "size_list=[1,10,50,100,250,500,1000,1500,3000,5000,7500,10000,15000,20000,25000,30000,35000,40000,45000,50000,55000,59500]\n",
        "acc_list=[]\n",
        "labeled_size=500\n",
        "for unlabel_size in size_list:\n",
        "  random.seed(0)\n",
        "  idxs_label = np.random.choice(x_train.shape[0], labeled_size, replace=False)\n",
        "  random.seed(1)\n",
        "  idxs_unlabel = np.random.choice(x_train.shape[0], unlabel_size, replace=False)\n",
        "  x_train_unlabeled = x_train[idxs_unlabel]\n",
        "  y_train_unlabeled = y_train[idxs_unlabel]\n",
        "  x_train_labeled   = x_train[idxs_label]\n",
        "  y_train_labeled   = y_train[idxs_label]\n",
        "  if unlabel_size>=labeled_size:\n",
        "    n_rep = x_train_unlabeled.shape[0] // x_train_labeled.shape[0]\n",
        "    x_train_labeled_rep = np.concatenate([x_train_labeled]*n_rep)\n",
        "    y_train_labeled_rep = np.concatenate([y_train_labeled]*n_rep)\n",
        "  else:\n",
        "    n_rep = x_train_labeled.shape[0] // x_train_unlabeled.shape[0]\n",
        "    x_train_unlabeled_rep = np.concatenate([x_train_unlabeled]*n_rep)\n",
        "    y_train_unlabeled_rep = np.concatenate([y_train_unlabeled]*n_rep)\n",
        "  \n",
        "  model = get_ladder_network_fc(layer_sizes=[inp_size, 1000, 500, 250, 250, 250, n_classes])\n",
        "\n",
        "  # train the model for 10 epochs\n",
        "  for _ in range(10):\n",
        "      if unlabel_size>=labeled_size:\n",
        "        model.fit([x_train_labeled_rep, x_train_unlabeled], y_train_labeled_rep, epochs=1)\n",
        "      else:\n",
        "        model.fit([x_train_labeled, x_train_unlabeled_rep], y_train_labeled, epochs=1)\n",
        "      y_test_pr = model.test_model.predict(x_test, batch_size=100)\n",
        "      acc=accuracy_score(y_test.argmax(-1), y_test_pr.argmax(-1))\n",
        "      print(\"Test accuracy : %f\" % acc)\n",
        "  acc_list.append(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "500/500 [==============================] - 47s 95ms/step - loss: 61.6274 - acc: 0.5040 - den_loss: 60.0070\n",
            "Test accuracy : 0.720300\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 10.3783 - acc: 0.6400 - den_loss: 9.2266\n",
            "Test accuracy : 0.771200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 7.8984 - acc: 0.6820 - den_loss: 6.7851\n",
            "Test accuracy : 0.770200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 6.3657 - acc: 0.7280 - den_loss: 5.3516\n",
            "Test accuracy : 0.798000\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 4.9233 - acc: 0.7260 - den_loss: 3.9208\n",
            "Test accuracy : 0.825500\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 3.6436 - acc: 0.7360 - den_loss: 2.6879\n",
            "Test accuracy : 0.823200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 2.6031 - acc: 0.7780 - den_loss: 1.7224\n",
            "Test accuracy : 0.828100\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.9454 - acc: 0.7740 - den_loss: 1.0661\n",
            "Test accuracy : 0.830800\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.5074 - acc: 0.8240 - den_loss: 0.6895\n",
            "Test accuracy : 0.834700\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 1.2474 - acc: 0.8160 - den_loss: 0.4271\n",
            "Test accuracy : 0.834600\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 47s 95ms/step - loss: 47.6968 - acc: 0.5340 - den_loss: 46.2209\n",
            "Test accuracy : 0.757400\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 13.8133 - acc: 0.7600 - den_loss: 12.8375\n",
            "Test accuracy : 0.832200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 9.2453 - acc: 0.8220 - den_loss: 8.4347\n",
            "Test accuracy : 0.858600\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 6.9787 - acc: 0.8260 - den_loss: 6.2261\n",
            "Test accuracy : 0.868300\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 5.3634 - acc: 0.8320 - den_loss: 4.5798\n",
            "Test accuracy : 0.867800\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 5.1408 - acc: 0.8680 - den_loss: 4.4611\n",
            "Test accuracy : 0.879700\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 4.8087 - acc: 0.8640 - den_loss: 4.1244\n",
            "Test accuracy : 0.868300\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 4.4186 - acc: 0.8800 - den_loss: 3.7496\n",
            "Test accuracy : 0.872700\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 4.6168 - acc: 0.9020 - den_loss: 3.9921\n",
            "Test accuracy : 0.876100\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 4.6668 - acc: 0.8980 - den_loss: 4.0527\n",
            "Test accuracy : 0.879200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 49s 97ms/step - loss: 53.0501 - acc: 0.5100 - den_loss: 51.4756\n",
            "Test accuracy : 0.774000\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 20.7612 - acc: 0.7100 - den_loss: 19.6699\n",
            "Test accuracy : 0.820600\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 16.7386 - acc: 0.8000 - den_loss: 15.8726\n",
            "Test accuracy : 0.845200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 14.1058 - acc: 0.8320 - den_loss: 13.3126\n",
            "Test accuracy : 0.854400\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 12.1844 - acc: 0.8460 - den_loss: 11.4371\n",
            "Test accuracy : 0.872600\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 10.9624 - acc: 0.8540 - den_loss: 10.2506\n",
            "Test accuracy : 0.858800\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 9.8607 - acc: 0.8560 - den_loss: 9.1468\n",
            "Test accuracy : 0.874300\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 9.2939 - acc: 0.9000 - den_loss: 8.6613\n",
            "Test accuracy : 0.869200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 8.7329 - acc: 0.9000 - den_loss: 8.1318\n",
            "Test accuracy : 0.869400\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 8.1919 - acc: 0.9040 - den_loss: 7.6019\n",
            "Test accuracy : 0.872500\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 51s 101ms/step - loss: 57.5427 - acc: 0.4960 - den_loss: 55.9850\n",
            "Test accuracy : 0.770200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 22.9236 - acc: 0.7320 - den_loss: 21.8948\n",
            "Test accuracy : 0.817700\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 18.8260 - acc: 0.8160 - den_loss: 17.9943\n",
            "Test accuracy : 0.840600\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 16.5912 - acc: 0.8140 - den_loss: 15.7865\n",
            "Test accuracy : 0.858100\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 15.4925 - acc: 0.8860 - den_loss: 14.8216\n",
            "Test accuracy : 0.846600\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 14.3274 - acc: 0.8700 - den_loss: 13.6903\n",
            "Test accuracy : 0.862200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 13.7049 - acc: 0.8780 - den_loss: 13.0531\n",
            "Test accuracy : 0.858100\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 12.8860 - acc: 0.8800 - den_loss: 12.2343\n",
            "Test accuracy : 0.859300\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 12.1900 - acc: 0.9180 - den_loss: 11.6179\n",
            "Test accuracy : 0.868900\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 11.5726 - acc: 0.8920 - den_loss: 10.9318\n",
            "Test accuracy : 0.871000\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 52s 104ms/step - loss: 58.7569 - acc: 0.5260 - den_loss: 57.2626\n",
            "Test accuracy : 0.813600\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 24.2369 - acc: 0.7760 - den_loss: 23.2973\n",
            "Test accuracy : 0.837100\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 20.7414 - acc: 0.8140 - den_loss: 19.9389\n",
            "Test accuracy : 0.853500\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 18.3203 - acc: 0.8440 - den_loss: 17.6001\n",
            "Test accuracy : 0.869000\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 17.4197 - acc: 0.8720 - den_loss: 16.7571\n",
            "Test accuracy : 0.873800\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 16.8007 - acc: 0.8960 - den_loss: 16.1714\n",
            "Test accuracy : 0.883400\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 16.1799 - acc: 0.9140 - den_loss: 15.5503\n",
            "Test accuracy : 0.885200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 15.8621 - acc: 0.8920 - den_loss: 15.2063\n",
            "Test accuracy : 0.889100\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 15.1219 - acc: 0.9320 - den_loss: 14.5490\n",
            "Test accuracy : 0.880700\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 14.9874 - acc: 0.9100 - den_loss: 14.3769\n",
            "Test accuracy : 0.890400\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 53s 106ms/step - loss: 59.8159 - acc: 0.5460 - den_loss: 58.3319\n",
            "Test accuracy : 0.781600\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 1ms/step - loss: 25.0374 - acc: 0.7380 - den_loss: 24.0516\n",
            "Test accuracy : 0.843200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 21.3152 - acc: 0.8080 - den_loss: 20.4722\n",
            "Test accuracy : 0.849900\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 19.2157 - acc: 0.8320 - den_loss: 18.4509\n",
            "Test accuracy : 0.872500\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 18.3316 - acc: 0.8600 - den_loss: 17.6431\n",
            "Test accuracy : 0.873600\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 17.6991 - acc: 0.8840 - den_loss: 17.0357\n",
            "Test accuracy : 0.884700\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 16.9994 - acc: 0.8820 - den_loss: 16.3695\n",
            "Test accuracy : 0.888400\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 16.7143 - acc: 0.9260 - den_loss: 16.1427\n",
            "Test accuracy : 0.892200\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 16.3194 - acc: 0.9300 - den_loss: 15.7599\n",
            "Test accuracy : 0.889400\n",
            "Epoch 1/1\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 15.9810 - acc: 0.9180 - den_loss: 15.3853\n",
            "Test accuracy : 0.889100\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 54s 54ms/step - loss: 42.1272 - acc: 0.6220 - den_loss: 40.8560\n",
            "Test accuracy : 0.825500\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 20.9336 - acc: 0.8210 - den_loss: 20.1290\n",
            "Test accuracy : 0.873600\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 18.6091 - acc: 0.8380 - den_loss: 17.8494\n",
            "Test accuracy : 0.870600\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 17.7032 - acc: 0.8920 - den_loss: 17.0296\n",
            "Test accuracy : 0.882200\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 16.9021 - acc: 0.9240 - den_loss: 16.3215\n",
            "Test accuracy : 0.878300\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 16.3802 - acc: 0.9070 - den_loss: 15.7849\n",
            "Test accuracy : 0.884600\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 15.7558 - acc: 0.9190 - den_loss: 15.1807\n",
            "Test accuracy : 0.885700\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 15.3343 - acc: 0.9230 - den_loss: 14.7647\n",
            "Test accuracy : 0.886700\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 14.9490 - acc: 0.9190 - den_loss: 14.3817\n",
            "Test accuracy : 0.888600\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 14.2588 - acc: 0.9440 - den_loss: 13.7142\n",
            "Test accuracy : 0.887100\n",
            "Epoch 1/1\n",
            "1500/1500 [==============================] - 56s 37ms/step - loss: 35.5870 - acc: 0.6527 - den_loss: 34.4120\n",
            "Test accuracy : 0.837300\n",
            "Epoch 1/1\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 19.2208 - acc: 0.8313 - den_loss: 18.4765\n",
            "Test accuracy : 0.865100\n",
            "Epoch 1/1\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 17.8160 - acc: 0.8980 - den_loss: 17.1859\n",
            "Test accuracy : 0.876400\n",
            "Epoch 1/1\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 16.6723 - acc: 0.9040 - den_loss: 16.0631\n",
            "Test accuracy : 0.873100\n",
            "Epoch 1/1\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 15.6336 - acc: 0.9327 - den_loss: 15.0780\n",
            "Test accuracy : 0.879000\n",
            "Epoch 1/1\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 15.0280 - acc: 0.9100 - den_loss: 14.4514\n",
            "Test accuracy : 0.878400\n",
            "Epoch 1/1\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 14.2080 - acc: 0.9353 - den_loss: 13.6636\n",
            "Test accuracy : 0.890400\n",
            "Epoch 1/1\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 13.9577 - acc: 0.9380 - den_loss: 13.4300\n",
            "Test accuracy : 0.890200\n",
            "Epoch 1/1\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 13.4680 - acc: 0.9480 - den_loss: 12.9549\n",
            "Test accuracy : 0.895900\n",
            "Epoch 1/1\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 13.1068 - acc: 0.9420 - den_loss: 12.5927\n",
            "Test accuracy : 0.896000\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 59s 20ms/step - loss: 27.2384 - acc: 0.7747 - den_loss: 26.3285\n",
            "Test accuracy : 0.881600\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 17.0616 - acc: 0.8993 - den_loss: 16.4392\n",
            "Test accuracy : 0.880700\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 15.5170 - acc: 0.9230 - den_loss: 14.9507\n",
            "Test accuracy : 0.903400\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 14.2317 - acc: 0.9287 - den_loss: 13.6823\n",
            "Test accuracy : 0.902800\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 13.4567 - acc: 0.9533 - den_loss: 12.9579\n",
            "Test accuracy : 0.908400\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 12.8646 - acc: 0.9617 - den_loss: 12.3888\n",
            "Test accuracy : 0.906600\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 12.4638 - acc: 0.9603 - den_loss: 11.9710\n",
            "Test accuracy : 0.910000\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 12.1632 - acc: 0.9623 - den_loss: 11.6768\n",
            "Test accuracy : 0.910300\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 11.8578 - acc: 0.9657 - den_loss: 11.3765\n",
            "Test accuracy : 0.913100\n",
            "Epoch 1/1\n",
            "3000/3000 [==============================] - 5s 2ms/step - loss: 11.7562 - acc: 0.9687 - den_loss: 11.2932\n",
            "Test accuracy : 0.913100\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 64s 13ms/step - loss: 23.5674 - acc: 0.8162 - den_loss: 22.7633\n",
            "Test accuracy : 0.878400\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 8s 2ms/step - loss: 15.7057 - acc: 0.9166 - den_loss: 15.1147\n",
            "Test accuracy : 0.897800\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 8s 2ms/step - loss: 13.9602 - acc: 0.9442 - den_loss: 13.4373\n",
            "Test accuracy : 0.893800\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 8s 2ms/step - loss: 13.0268 - acc: 0.9582 - den_loss: 12.5358\n",
            "Test accuracy : 0.908000\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 8s 2ms/step - loss: 12.3729 - acc: 0.9700 - den_loss: 11.9058\n",
            "Test accuracy : 0.910300\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 8s 2ms/step - loss: 11.9830 - acc: 0.9680 - den_loss: 11.5155\n",
            "Test accuracy : 0.905100\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 8s 2ms/step - loss: 11.7634 - acc: 0.9662 - den_loss: 11.2890\n",
            "Test accuracy : 0.910300\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 8s 2ms/step - loss: 11.5425 - acc: 0.9678 - den_loss: 11.0718\n",
            "Test accuracy : 0.909100\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 8s 2ms/step - loss: 11.3790 - acc: 0.9718 - den_loss: 10.9178\n",
            "Test accuracy : 0.913200\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 8s 2ms/step - loss: 11.2119 - acc: 0.9738 - den_loss: 10.7521\n",
            "Test accuracy : 0.918000\n",
            "Epoch 1/1\n",
            "7500/7500 [==============================] - 68s 9ms/step - loss: 21.0600 - acc: 0.8603 - den_loss: 20.3572\n",
            "Test accuracy : 0.871700\n",
            "Epoch 1/1\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 14.2494 - acc: 0.9408 - den_loss: 13.7248\n",
            "Test accuracy : 0.900600\n",
            "Epoch 1/1\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 12.7811 - acc: 0.9580 - den_loss: 12.2915\n",
            "Test accuracy : 0.914900\n",
            "Epoch 1/1\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 12.0461 - acc: 0.9660 - den_loss: 11.5667\n",
            "Test accuracy : 0.911500\n",
            "Epoch 1/1\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 11.6358 - acc: 0.9711 - den_loss: 11.1762\n",
            "Test accuracy : 0.914700\n",
            "Epoch 1/1\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 11.4357 - acc: 0.9737 - den_loss: 10.9771\n",
            "Test accuracy : 0.910200\n",
            "Epoch 1/1\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 11.3145 - acc: 0.9707 - den_loss: 10.8482\n",
            "Test accuracy : 0.924700\n",
            "Epoch 1/1\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 11.1390 - acc: 0.9779 - den_loss: 10.6833\n",
            "Test accuracy : 0.926400\n",
            "Epoch 1/1\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 11.0249 - acc: 0.9783 - den_loss: 10.5761\n",
            "Test accuracy : 0.923900\n",
            "Epoch 1/1\n",
            "7500/7500 [==============================] - 12s 2ms/step - loss: 10.9426 - acc: 0.9791 - den_loss: 10.4955\n",
            "Test accuracy : 0.928500\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 75s 8ms/step - loss: 19.6641 - acc: 0.8834 - den_loss: 19.0029\n",
            "Test accuracy : 0.871300\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 13.3599 - acc: 0.9529 - den_loss: 12.8560\n",
            "Test accuracy : 0.899600\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 16s 2ms/step - loss: 12.1420 - acc: 0.9661 - den_loss: 11.6644\n",
            "Test accuracy : 0.906600\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 16s 2ms/step - loss: 11.6690 - acc: 0.9713 - den_loss: 11.2127\n",
            "Test accuracy : 0.901700\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 16s 2ms/step - loss: 11.3056 - acc: 0.9736 - den_loss: 10.8480\n",
            "Test accuracy : 0.912400\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 16s 2ms/step - loss: 11.1289 - acc: 0.9793 - den_loss: 10.6770\n",
            "Test accuracy : 0.920600\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 11.0072 - acc: 0.9802 - den_loss: 10.5643\n",
            "Test accuracy : 0.918500\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 16s 2ms/step - loss: 10.8641 - acc: 0.9834 - den_loss: 10.4239\n",
            "Test accuracy : 0.926700\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 16s 2ms/step - loss: 10.8094 - acc: 0.9834 - den_loss: 10.3706\n",
            "Test accuracy : 0.924800\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 16s 2ms/step - loss: 10.6077 - acc: 0.9829 - den_loss: 10.1638\n",
            "Test accuracy : 0.930300\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 84s 6ms/step - loss: 17.6706 - acc: 0.9001 - den_loss: 17.0442\n",
            "Test accuracy : 0.903400\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 24s 2ms/step - loss: 12.3800 - acc: 0.9641 - den_loss: 11.8986\n",
            "Test accuracy : 0.916600\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 24s 2ms/step - loss: 11.5446 - acc: 0.9723 - den_loss: 11.0786\n",
            "Test accuracy : 0.919500\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 23s 2ms/step - loss: 11.2152 - acc: 0.9756 - den_loss: 10.7597\n",
            "Test accuracy : 0.923600\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 24s 2ms/step - loss: 10.9954 - acc: 0.9786 - den_loss: 10.5438\n",
            "Test accuracy : 0.930500\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 24s 2ms/step - loss: 10.7922 - acc: 0.9821 - den_loss: 10.3507\n",
            "Test accuracy : 0.932000\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 24s 2ms/step - loss: 10.6583 - acc: 0.9831 - den_loss: 10.2196\n",
            "Test accuracy : 0.928900\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 23s 2ms/step - loss: 10.5554 - acc: 0.9856 - den_loss: 10.1223\n",
            "Test accuracy : 0.935200\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 24s 2ms/step - loss: 10.4346 - acc: 0.9865 - den_loss: 9.9974\n",
            "Test accuracy : 0.937200\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 24s 2ms/step - loss: 10.3705 - acc: 0.9869 - den_loss: 9.9401\n",
            "Test accuracy : 0.937000\n",
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 91s 5ms/step - loss: 16.4976 - acc: 0.9132 - den_loss: 15.8980\n",
            "Test accuracy : 0.906300\n",
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 31s 2ms/step - loss: 11.9434 - acc: 0.9718 - den_loss: 11.4785\n",
            "Test accuracy : 0.907700\n",
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 32s 2ms/step - loss: 11.3224 - acc: 0.9771 - den_loss: 10.8687\n",
            "Test accuracy : 0.916800\n",
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 32s 2ms/step - loss: 10.9742 - acc: 0.9806 - den_loss: 10.5262\n",
            "Test accuracy : 0.922100\n",
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 32s 2ms/step - loss: 10.8153 - acc: 0.9837 - den_loss: 10.3745\n",
            "Test accuracy : 0.927800\n",
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 31s 2ms/step - loss: 10.6190 - acc: 0.9846 - den_loss: 10.1808\n",
            "Test accuracy : 0.929800\n",
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 31s 2ms/step - loss: 10.5558 - acc: 0.9866 - den_loss: 10.1216\n",
            "Test accuracy : 0.935400\n",
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 32s 2ms/step - loss: 10.3865 - acc: 0.9873 - den_loss: 9.9513\n",
            "Test accuracy : 0.941000\n",
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 32s 2ms/step - loss: 10.3031 - acc: 0.9873 - den_loss: 9.8724\n",
            "Test accuracy : 0.939800\n",
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 32s 2ms/step - loss: 10.2021 - acc: 0.9873 - den_loss: 9.7696\n",
            "Test accuracy : 0.939800\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 101s 4ms/step - loss: 15.6180 - acc: 0.9312 - den_loss: 15.0619\n",
            "Test accuracy : 0.898600\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 39s 2ms/step - loss: 11.6287 - acc: 0.9725 - den_loss: 11.1657\n",
            "Test accuracy : 0.918500\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 40s 2ms/step - loss: 11.0911 - acc: 0.9793 - den_loss: 10.6456\n",
            "Test accuracy : 0.920500\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 39s 2ms/step - loss: 10.8039 - acc: 0.9814 - den_loss: 10.3590\n",
            "Test accuracy : 0.930400\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 40s 2ms/step - loss: 10.5711 - acc: 0.9848 - den_loss: 10.1333\n",
            "Test accuracy : 0.936600\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 40s 2ms/step - loss: 10.4337 - acc: 0.9864 - den_loss: 10.0004\n",
            "Test accuracy : 0.934300\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 41s 2ms/step - loss: 10.3079 - acc: 0.9858 - den_loss: 9.8678\n",
            "Test accuracy : 0.937500\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 41s 2ms/step - loss: 10.2251 - acc: 0.9890 - den_loss: 9.7983\n",
            "Test accuracy : 0.942300\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 41s 2ms/step - loss: 10.0837 - acc: 0.9898 - den_loss: 9.6587\n",
            "Test accuracy : 0.945500\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 39s 2ms/step - loss: 9.9802 - acc: 0.9903 - den_loss: 9.5510\n",
            "Test accuracy : 0.944900\n",
            "Epoch 1/1\n",
            "30000/30000 [==============================] - 110s 4ms/step - loss: 15.1283 - acc: 0.9276 - den_loss: 14.5665\n",
            "Test accuracy : 0.905600\n",
            "Epoch 1/1\n",
            "30000/30000 [==============================] - 50s 2ms/step - loss: 11.4848 - acc: 0.9745 - den_loss: 11.0289\n",
            "Test accuracy : 0.914800\n",
            "Epoch 1/1\n",
            "30000/30000 [==============================] - 48s 2ms/step - loss: 11.0194 - acc: 0.9781 - den_loss: 10.5713\n",
            "Test accuracy : 0.933300\n",
            "Epoch 1/1\n",
            "30000/30000 [==============================] - 48s 2ms/step - loss: 10.6780 - acc: 0.9829 - den_loss: 10.2398\n",
            "Test accuracy : 0.937500\n",
            "Epoch 1/1\n",
            "30000/30000 [==============================] - 48s 2ms/step - loss: 10.4771 - acc: 0.9843 - den_loss: 10.0401\n",
            "Test accuracy : 0.934900\n",
            "Epoch 1/1\n",
            "30000/30000 [==============================] - 48s 2ms/step - loss: 10.3233 - acc: 0.9841 - den_loss: 9.8842\n",
            "Test accuracy : 0.938900\n",
            "Epoch 1/1\n",
            "30000/30000 [==============================] - 47s 2ms/step - loss: 10.2244 - acc: 0.9862 - den_loss: 9.7901\n",
            "Test accuracy : 0.943200\n",
            "Epoch 1/1\n",
            "30000/30000 [==============================] - 48s 2ms/step - loss: 10.0914 - acc: 0.9899 - den_loss: 9.6646\n",
            "Test accuracy : 0.946500\n",
            "Epoch 1/1\n",
            "30000/30000 [==============================] - 48s 2ms/step - loss: 9.9865 - acc: 0.9892 - den_loss: 9.5592\n",
            "Test accuracy : 0.950900\n",
            "Epoch 1/1\n",
            "30000/30000 [==============================] - 49s 2ms/step - loss: 9.9280 - acc: 0.9905 - den_loss: 9.5007\n",
            "Test accuracy : 0.952400\n",
            "Epoch 1/1\n",
            "35000/35000 [==============================] - 120s 3ms/step - loss: 14.5932 - acc: 0.9412 - den_loss: 14.0616\n",
            "Test accuracy : 0.907600\n",
            "Epoch 1/1\n",
            "35000/35000 [==============================] - 57s 2ms/step - loss: 11.2932 - acc: 0.9765 - den_loss: 10.8363\n",
            "Test accuracy : 0.922000\n",
            "Epoch 1/1\n",
            "35000/35000 [==============================] - 55s 2ms/step - loss: 10.8484 - acc: 0.9841 - den_loss: 10.4095\n",
            "Test accuracy : 0.930600\n",
            "Epoch 1/1\n",
            "35000/35000 [==============================] - 56s 2ms/step - loss: 10.5589 - acc: 0.9843 - den_loss: 10.1193\n",
            "Test accuracy : 0.934900\n",
            "Epoch 1/1\n",
            "35000/35000 [==============================] - 56s 2ms/step - loss: 10.3727 - acc: 0.9862 - den_loss: 9.9369\n",
            "Test accuracy : 0.938300\n",
            "Epoch 1/1\n",
            "35000/35000 [==============================] - 56s 2ms/step - loss: 10.2142 - acc: 0.9884 - den_loss: 9.7843\n",
            "Test accuracy : 0.934000\n",
            "Epoch 1/1\n",
            "35000/35000 [==============================] - 56s 2ms/step - loss: 10.0782 - acc: 0.9901 - den_loss: 9.6555\n",
            "Test accuracy : 0.947600\n",
            "Epoch 1/1\n",
            "35000/35000 [==============================] - 57s 2ms/step - loss: 9.9736 - acc: 0.9906 - den_loss: 9.5497\n",
            "Test accuracy : 0.948600\n",
            "Epoch 1/1\n",
            "35000/35000 [==============================] - 56s 2ms/step - loss: 9.8656 - acc: 0.9906 - den_loss: 9.4395\n",
            "Test accuracy : 0.944100\n",
            "Epoch 1/1\n",
            "35000/35000 [==============================] - 55s 2ms/step - loss: 9.7660 - acc: 0.9921 - den_loss: 9.3437\n",
            "Test accuracy : 0.948800\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 129s 3ms/step - loss: 14.3131 - acc: 0.9388 - den_loss: 13.7763\n",
            "Test accuracy : 0.914700\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 65s 2ms/step - loss: 11.2491 - acc: 0.9790 - den_loss: 10.8007\n",
            "Test accuracy : 0.929000\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 66s 2ms/step - loss: 10.7916 - acc: 0.9795 - den_loss: 10.3432\n",
            "Test accuracy : 0.932800\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 65s 2ms/step - loss: 10.5110 - acc: 0.9841 - den_loss: 10.0713\n",
            "Test accuracy : 0.936500\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 65s 2ms/step - loss: 10.3355 - acc: 0.9861 - den_loss: 9.9024\n",
            "Test accuracy : 0.938700\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 65s 2ms/step - loss: 10.1341 - acc: 0.9870 - den_loss: 9.7018\n",
            "Test accuracy : 0.945800\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 67s 2ms/step - loss: 9.9979 - acc: 0.9891 - den_loss: 9.5701\n",
            "Test accuracy : 0.949400\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 65s 2ms/step - loss: 9.8869 - acc: 0.9904 - den_loss: 9.4625\n",
            "Test accuracy : 0.949400\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 66s 2ms/step - loss: 9.8005 - acc: 0.9912 - den_loss: 9.3734\n",
            "Test accuracy : 0.951300\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 65s 2ms/step - loss: 9.7422 - acc: 0.9916 - den_loss: 9.3161\n",
            "Test accuracy : 0.953600\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 143s 3ms/step - loss: 13.9307 - acc: 0.9466 - den_loss: 13.4116\n",
            "Test accuracy : 0.918900\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 75s 2ms/step - loss: 11.0519 - acc: 0.9802 - den_loss: 10.6112\n",
            "Test accuracy : 0.937200\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 74s 2ms/step - loss: 10.6296 - acc: 0.9848 - den_loss: 10.1947\n",
            "Test accuracy : 0.941300\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 75s 2ms/step - loss: 10.3570 - acc: 0.9873 - den_loss: 9.9268\n",
            "Test accuracy : 0.946600\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 75s 2ms/step - loss: 10.1738 - acc: 0.9890 - den_loss: 9.7475\n",
            "Test accuracy : 0.948200\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 74s 2ms/step - loss: 10.0135 - acc: 0.9901 - den_loss: 9.5892\n",
            "Test accuracy : 0.950600\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 75s 2ms/step - loss: 9.8804 - acc: 0.9918 - den_loss: 9.4601\n",
            "Test accuracy : 0.952700\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 73s 2ms/step - loss: 9.7798 - acc: 0.9920 - den_loss: 9.3576\n",
            "Test accuracy : 0.955100\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 75s 2ms/step - loss: 9.7192 - acc: 0.9933 - den_loss: 9.3027\n",
            "Test accuracy : 0.958100\n",
            "Epoch 1/1\n",
            "45000/45000 [==============================] - 74s 2ms/step - loss: 9.6308 - acc: 0.9934 - den_loss: 9.2111\n",
            "Test accuracy : 0.961400\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 149s 3ms/step - loss: 13.6909 - acc: 0.9525 - den_loss: 13.1843\n",
            "Test accuracy : 0.909600\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 83s 2ms/step - loss: 11.0055 - acc: 0.9813 - den_loss: 10.5588\n",
            "Test accuracy : 0.939700\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 82s 2ms/step - loss: 10.5542 - acc: 0.9850 - den_loss: 10.1184\n",
            "Test accuracy : 0.934200\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 83s 2ms/step - loss: 10.3059 - acc: 0.9867 - den_loss: 9.8739\n",
            "Test accuracy : 0.945100\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 82s 2ms/step - loss: 10.1232 - acc: 0.9900 - den_loss: 9.6971\n",
            "Test accuracy : 0.942400\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 82s 2ms/step - loss: 9.9950 - acc: 0.9906 - den_loss: 9.5673\n",
            "Test accuracy : 0.950600\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 84s 2ms/step - loss: 9.8536 - acc: 0.9927 - den_loss: 9.4314\n",
            "Test accuracy : 0.954300\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 84s 2ms/step - loss: 9.7237 - acc: 0.9929 - den_loss: 9.3023\n",
            "Test accuracy : 0.954200\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 84s 2ms/step - loss: 9.6774 - acc: 0.9938 - den_loss: 9.2598\n",
            "Test accuracy : 0.954900\n",
            "Epoch 1/1\n",
            "50000/50000 [==============================] - 83s 2ms/step - loss: 9.5992 - acc: 0.9937 - den_loss: 9.1810\n",
            "Test accuracy : 0.960200\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 162s 3ms/step - loss: 13.4526 - acc: 0.9493 - den_loss: 12.9401\n",
            "Test accuracy : 0.918400\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 92s 2ms/step - loss: 10.9121 - acc: 0.9813 - den_loss: 10.4672\n",
            "Test accuracy : 0.936100\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 92s 2ms/step - loss: 10.4846 - acc: 0.9853 - den_loss: 10.0484\n",
            "Test accuracy : 0.942400\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 91s 2ms/step - loss: 10.2489 - acc: 0.9885 - den_loss: 9.8216\n",
            "Test accuracy : 0.948600\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 91s 2ms/step - loss: 10.0178 - acc: 0.9904 - den_loss: 9.5921\n",
            "Test accuracy : 0.945000\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 90s 2ms/step - loss: 9.8965 - acc: 0.9912 - den_loss: 9.4705\n",
            "Test accuracy : 0.950100\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 90s 2ms/step - loss: 9.7473 - acc: 0.9925 - den_loss: 9.3273\n",
            "Test accuracy : 0.952300\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 91s 2ms/step - loss: 9.6822 - acc: 0.9929 - den_loss: 9.2587\n",
            "Test accuracy : 0.950800\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 90s 2ms/step - loss: 9.5777 - acc: 0.9939 - den_loss: 9.1586\n",
            "Test accuracy : 0.958500\n",
            "Epoch 1/1\n",
            "55000/55000 [==============================] - 91s 2ms/step - loss: 9.5100 - acc: 0.9942 - den_loss: 9.0921\n",
            "Test accuracy : 0.952400\n",
            "Epoch 1/1\n",
            "59500/59500 [==============================] - 168s 3ms/step - loss: 13.2901 - acc: 0.9530 - den_loss: 12.7856\n",
            "Test accuracy : 0.923300\n",
            "Epoch 1/1\n",
            "59500/59500 [==============================] - 99s 2ms/step - loss: 10.8463 - acc: 0.9821 - den_loss: 10.4049\n",
            "Test accuracy : 0.926900\n",
            "Epoch 1/1\n",
            "59500/59500 [==============================] - 101s 2ms/step - loss: 10.4654 - acc: 0.9861 - den_loss: 10.0326\n",
            "Test accuracy : 0.943400\n",
            "Epoch 1/1\n",
            "59500/59500 [==============================] - 99s 2ms/step - loss: 10.1756 - acc: 0.9889 - den_loss: 9.7469\n",
            "Test accuracy : 0.940500\n",
            "Epoch 1/1\n",
            "59500/59500 [==============================] - 100s 2ms/step - loss: 9.9839 - acc: 0.9898 - den_loss: 9.5575\n",
            "Test accuracy : 0.951300\n",
            "Epoch 1/1\n",
            "59500/59500 [==============================] - 99s 2ms/step - loss: 9.8285 - acc: 0.9921 - den_loss: 9.4092\n",
            "Test accuracy : 0.951900\n",
            "Epoch 1/1\n",
            "59500/59500 [==============================] - 100s 2ms/step - loss: 9.6929 - acc: 0.9924 - den_loss: 9.2692\n",
            "Test accuracy : 0.950900\n",
            "Epoch 1/1\n",
            "59500/59500 [==============================] - 103s 2ms/step - loss: 9.5996 - acc: 0.9937 - den_loss: 9.1818\n",
            "Test accuracy : 0.956400\n",
            "Epoch 1/1\n",
            "59500/59500 [==============================] - 100s 2ms/step - loss: 9.5381 - acc: 0.9937 - den_loss: 9.1203\n",
            "Test accuracy : 0.957100\n",
            "Epoch 1/1\n",
            "59500/59500 [==============================] - 100s 2ms/step - loss: 9.4655 - acc: 0.9941 - den_loss: 9.0463\n",
            "Test accuracy : 0.958500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEWhR3dH3M1l",
        "colab_type": "code",
        "outputId": "fcdce8ba-2c83-47f5-d258-4f099af7df0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "size_list_plot=np.array(size_list)\n",
        "plt.plot(size_list_plot/500, acc_list)  \n",
        "plt.title(\"Test accuracy vs the ratio of unlabeled data and labeled data\")\n",
        "plt.xlabel(\"number of unlabeled data as multiple of labeled data\")\n",
        "plt.ylabel(\"test accuracy\")\n",
        "\n",
        "plt.ylim(0.8, 1)\n",
        "plt.show()  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEWCAYAAAAgpUMxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD0DOOefywgOQc865vPj/ab4DVc0p6cUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeKkb1ZEMIxp",
        "colab_type": "code",
        "outputId": "74c41532-9502-491d-b5b3-716cd70da3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(acc_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7407, 0.8084, 0.8477, 0.8715, 0.8735, 0.8879, 0.8754, 0.8795, 0.883, 0.8894, 0.8327, 0.8576, 0.8726, 0.8753, 0.8757, 0.88, 0.8916, 0.8808, 0.8895, 0.8828, 0.8731, 0.8839, 0.8872, 0.8946, 0.8998, 0.8991, 0.8962, 0.8964, 0.8971, 0.8996, 0.8706, 0.8748, 0.8877, 0.8974, 0.8961, 0.9005, 0.8963, 0.9052, 0.9098, 0.9076, 0.8912, 0.9031, 0.9099, 0.9173, 0.9132, 0.9242, 0.9195, 0.9252, 0.9274, 0.9324, 0.8968, 0.9141, 0.9158, 0.9281, 0.9289, 0.926, 0.9338, 0.9396, 0.9418, 0.9391, 0.9084, 0.9129, 0.9146, 0.9311, 0.9236, 0.9374, 0.9318, 0.9471, 0.9431, 0.948, 0.9072, 0.9225, 0.9279, 0.9286, 0.9445, 0.9425, 0.9453, 0.948, 0.9502, 0.9448, 0.9177, 0.9251, 0.9358, 0.938, 0.9391, 0.9457, 0.949, 0.9469, 0.9529, 0.9542, 0.9189, 0.9318, 0.9391, 0.9414, 0.9456, 0.9515, 0.9487, 0.9517, 0.951, 0.9552, 0.9058, 0.9233, 0.9297, 0.9322, 0.9431, 0.9444, 0.9522, 0.9538, 0.951, 0.9529, 0.9172, 0.9269, 0.9285, 0.9406, 0.9465, 0.9462, 0.9538, 0.9513, 0.9504, 0.9546, 0.9147, 0.9366, 0.9375, 0.9469, 0.9468, 0.9538, 0.9491, 0.9541, 0.9624, 0.9596, 0.9236, 0.9382, 0.9406, 0.9491, 0.9504, 0.9536, 0.9551, 0.9586, 0.9577, 0.9601]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}